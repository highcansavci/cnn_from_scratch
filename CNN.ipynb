{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from random import shuffle\n",
    "import glob\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "NUMBER_OF_CLASSES = 10\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    \"\"\"\n",
    "    Prepares MNIST the training data and the test data, as a hdf5 file.\n",
    "    \"\"\"\n",
    "    hdf5_train_file = \"C:\\\\Users\\\\lenovo\\\\train.hdf5\"\n",
    "    hdf5_test_file = \"C:\\\\Users\\\\lenovo\\\\test.hdf5\"\n",
    "    train = h5py.File(hdf5_train_file, \"r\")\n",
    "    test = h5py.File(hdf5_test_file, \"r\")\n",
    "    [print(item) for item in train.items()]\n",
    "    [print(item) for item in test.items()]\n",
    "    train_x = np.pad(np.array(train[\"image\"]), ((0, 0), (2, 2), (2, 2)), mode=\"constant\", constant_values=0)\n",
    "    test_x = np.pad(np.array(test[\"image\"]), ((0, 0), (2, 2), (2, 2)), mode=\"constant\", constant_values=0)\n",
    "    train_y = np.eye(NUMBER_OF_CLASSES)[train[\"label\"]]\n",
    "    test_y = np.eye(NUMBER_OF_CLASSES)[test[\"label\"]]\n",
    "    \n",
    "    # Shuffles the training data and validation data\n",
    "    train_perm = np.random.permutation(train_x.shape[0])\n",
    "    test_perm = np.random.permutation(test_x.shape[0])\n",
    "    \n",
    "    return train_x[train_perm], train_y[train_perm], test_x[test_perm], test_y[test_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('image', <HDF5 dataset \"image\": shape (60000, 28, 28), type \"|u1\">)\n",
      "('label', <HDF5 dataset \"label\": shape (60000,), type \"|u1\">)\n",
      "('image', <HDF5 dataset \"image\": shape (10000, 28, 28), type \"|u1\">)\n",
      "('label', <HDF5 dataset \"label\": shape (10000,), type \"|u1\">)\n",
      "(32, 32)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 60000\n",
      "Number of testing examples: 10000\n",
      "Each image is of size: (32, 32)\n",
      "train_x_orig shape: (60000, 32, 32, 1)\n",
      "train_y shape: (60000, 10)\n",
      "test_x_orig shape: (10000, 32, 32, 1)\n",
      "test_y shape: (10000, 10)\n",
      "-----------------------------\n",
      "train_y shape: (10, 60000)\n",
      "test_y shape: (10, 10000)\n",
      "train_x shape: (60000, 32, 32, 1)\n",
      "test_x shape: (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Extract a dataset from hdf5 file, resize and normalize the image arrays.\n",
    "m_train = train_x.shape[0]\n",
    "num_px = train_x.shape[1]\n",
    "m_test = test_x.shape[0]\n",
    "\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples: \" + str(m_test))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \")\")\n",
    "print (\"train_x_orig shape: \" + str(train_x.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x_orig shape: \" + str(test_x.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))\n",
    "\n",
    "train_x = np.array(train_x).reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n",
    "test_x = np.array(test_x).reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n",
    "train_y = np.array(train_y).T\n",
    "test_y = np.array(test_y).T\n",
    "\n",
    "\n",
    "train_x = train_x / 255\n",
    "test_x = test_x / 255\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "print(\"train_y shape: \" + str(train_y.shape))\n",
    "print(\"test_y shape: \" + str(test_y.shape))\n",
    "print(\"train_x shape: \" + str(train_x.shape))\n",
    "print(\"test_x shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(train_x, train_y, mini_batch_size=64):\n",
    "    \"\"\"\n",
    "    Create mini batches with the size mini_batch_size\n",
    "    \"\"\"\n",
    "    mini_batches = []\n",
    "    num_minibatch = math.floor(train_x.shape[0] / mini_batch_size)\n",
    "    for i in range(0, num_minibatch):\n",
    "        mini_batch_x = train_x[i * mini_batch_size: (i + 1) * mini_batch_size, ...]\n",
    "        mini_batch_y = train_y[:, i * mini_batch_size: (i + 1) * mini_batch_size]\n",
    "        mini_batch = (mini_batch_x, mini_batch_y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    if train_x.shape[0] % mini_batch_size != 0:\n",
    "        mini_batch_x = train_x[i * mini_batch_size:, ...]\n",
    "        mini_batch_y = train_y[:, i * mini_batch_size:]\n",
    "        mini_batch = (mini_batch_x, mini_batch_y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(train_x, nn_class=2):\n",
    "    model = {}\n",
    "    sample = train_x[0].shape\n",
    "    shape = sample[0]\n",
    "    channel = sample[2]\n",
    "    model[0] = {}\n",
    "    model[0]['conv0'] = {}\n",
    "    model[0]['conv0']['channel_size'] = channel\n",
    "    cnn_layer_size = int(input(\"How many convolutional layers do you want: \"))\n",
    "    count_layer = 1\n",
    "    prev_type = ''\n",
    "    conv_no = 1\n",
    "    while count_layer <= cnn_layer_size:\n",
    "        hyperparameters = {}\n",
    "        layer_type = input(\"State the layer type : \")\n",
    "        assert(layer_type == 'conv' or layer_type == 'pool')\n",
    "        if layer_type == 'conv':\n",
    "            if prev_type == 'pool' or prev_type == 'conv':\n",
    "                count_layer += 1\n",
    "                if count_layer > cnn_layer_size:\n",
    "                    print('The last convolution layer is not added, the CNN model is constructed.')\n",
    "                    break\n",
    "            hyperparameters['layer_type'] = 'conv'\n",
    "            f = int(input('State the layer size ' + str(count_layer) + ' : '))\n",
    "            assert(f <= shape)\n",
    "            hyperparameters['f'] = f\n",
    "            stride = int(input('State the stride size ' + str(count_layer) + ' : '))\n",
    "            assert(stride <= shape - f)\n",
    "            hyperparameters['stride'] = stride\n",
    "            pad = input('State the pad type ' + str(count_layer) + ' : ').upper()\n",
    "            assert(pad == 'VALID' or pad == 'SAME')\n",
    "            hyperparameters['pad'] = pad\n",
    "            if pad == 'VALID':\n",
    "                pad = 0\n",
    "            else:\n",
    "                pad = (f - 1) // 2\n",
    "            conv_channel = int(input('State the channel size ' + str(count_layer) + ' : '))\n",
    "            assert(conv_channel >= channel)\n",
    "            hyperparameters['channel_size'] = conv_channel\n",
    "            channel = conv_channel\n",
    "            model[count_layer] = {}\n",
    "            model[count_layer][layer_type + str(count_layer)] = hyperparameters\n",
    "            conv_no = 1\n",
    "            prev_type = 'conv'\n",
    "        elif layer_type == 'pool':\n",
    "            hyperparameters['layer_type'] = 'pool'\n",
    "            f = int(input('State the layer size ' + str(count_layer) + ' : '))\n",
    "            assert(f <= shape)\n",
    "            hyperparameters['f'] = f\n",
    "            stride = int(input('State the stride size ' + str(count_layer) + ' : '))\n",
    "            assert(stride <= shape - f)\n",
    "            hyperparameters['stride'] = stride\n",
    "            pool_type = input(\"State the type of layer \" + str(count_layer) + \" and pooling layer \" + str(conv_no) + ' : ')\n",
    "            assert(pool_type == 'max' or pool_type == 'average')\n",
    "            hyperparameters['mode'] = pool_type\n",
    "            model[count_layer_prev][layer_type + str(conv_no)] = hyperparameters\n",
    "            pad = 0\n",
    "            conv_no += 1\n",
    "            prev_type = 'pool'\n",
    "        shape = (shape - f + 2 * pad) // stride + 1\n",
    "        count_layer_prev = count_layer\n",
    "    model['fc0'] = {}\n",
    "    model['fc0']['shape'] = (-1, shape, shape, channel)\n",
    "    model['fc0']['fc_size'] = flatten = channel * shape ** 2\n",
    "    fc_layer_size = int(input(\"How many fully connected layers do you want (output layer included): \"))\n",
    "    for j in range(1, fc_layer_size + 1):\n",
    "        model['fc' + str(j)] = {}\n",
    "        if j != fc_layer_size:\n",
    "            model['fc' + str(j)]['activation'] = 'relu' \n",
    "            fc_size = int(input(\"State the fully connected layer \" + str(j) + ' size: '))\n",
    "        else:\n",
    "            if nn_class > 2:\n",
    "                model['fc' + str(j)]['activation'] = 'softmax'\n",
    "                fc_size = nn_class\n",
    "            elif nn_class > 0:\n",
    "                model['fc' + str(j)]['activation'] = 'sigmoid'\n",
    "                fc_size = 1\n",
    "            else:\n",
    "                raise Exception('The number of classes should be bigger than 0.')\n",
    "        assert(flatten >= fc_size)\n",
    "        model['fc' + str(j)]['fc_size'] = fc_size \n",
    "        flatten = fc_size\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(model):\n",
    "    \"\"\"\n",
    "    Initialize the weights randomly using the Gaussian RV.\n",
    "    Initialize the bias using the zeros.\n",
    "    \"\"\"\n",
    "    weight_bias = {}\n",
    "    layer_no = 1\n",
    "    for layer in model.keys():\n",
    "        if type(layer) == int and layer > 0:\n",
    "            weight_bias['W' + str(layer)] = np.random.randn(model[layer]['conv' + str(layer)]['f'], model[layer]['conv' + str(layer)]['f'], model[layer - 1]['conv' + str(layer - 1)]['channel_size'], model[layer]['conv' + str(layer)]['channel_size']) * np.sqrt(2./model[layer]['conv' + str(layer)]['f'])\n",
    "            weight_bias['b' + str(layer)] = np.zeros((1, 1, 1, model[layer]['conv' + str(layer)]['channel_size']))\n",
    "        elif layer == 'fc0' or layer == 0:\n",
    "            pass\n",
    "        else:\n",
    "            layer_no = int(layer[-1])\n",
    "            weight_bias['WFC' + layer[-1]] = np.random.randn(model['fc' + layer[-1]]['fc_size'], model['fc' + str(layer_no - 1)]['fc_size']) * np.sqrt(2./model['fc' + str(layer_no - 1)]['fc_size'])\n",
    "            weight_bias['bFC' + layer[-1]] = np.zeros((model['fc' + layer[-1]]['fc_size'], 1))\n",
    "    return weight_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(train_x, pad):\n",
    "    return np.pad(train_x, ((0, 0), (pad, pad), (pad, pad), (0, 0)), mode='constant', constant_values=(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(activation_slice_prev, weight, bias):\n",
    "    return np.sum(activation_slice_prev * weight) + float(bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(activation_prev, weights, biases, hyperparameters):\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = activation_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = weights.shape\n",
    "    stride = int(hyperparameters['stride'])\n",
    "    if hyperparameters['pad'] == 'VALID':\n",
    "        pad = 0\n",
    "    else:\n",
    "        pad = (f - 1) // 2\n",
    "    n_H = (n_H_prev - f + 2 * pad) // stride + 1\n",
    "    n_W = (n_W_prev - f + 2 * pad) // stride + 1\n",
    "    z = np.zeros((m, n_H, n_W, n_C))\n",
    "    activation_prev_pad = zero_pad(activation_prev, pad)\n",
    "    for i in range(m):\n",
    "        act_prev_pad = activation_prev_pad[i]\n",
    "        for h in range(n_H):\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "            for w in range(n_W):\n",
    "                horiz_start = w * stride\n",
    "                horiz_end = horiz_start + f\n",
    "                for c in range(n_C):\n",
    "                    act_slice_prev = act_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    weight = weights[...,c]\n",
    "                    bias = biases[..., c]\n",
    "                    z[i, h, w, c] = conv_single_step(act_slice_prev, weight, bias) \n",
    "    assert(z.shape == (m, n_H, n_W, n_C))\n",
    "    cache = (activation_prev, weights, biases, hyperparameters)\n",
    "    return z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_relu(linear_z, leaky=False, leaky_rate=0):\n",
    "    \"\"\"\n",
    "    Calculate the relu and leaky relu activation function\n",
    "    Return the activation output, activation input and the type of activation function.\n",
    "    \"\"\"\n",
    "    return np.maximum(leaky_rate * linear_z, linear_z), linear_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_sigmoid(linear_z):\n",
    "    \"\"\"\n",
    "    Calculate the sigmoid activation function\n",
    "    Return the activation output, activation input and the type of activation function.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-linear_z)), linear_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_softmax(linear_z):\n",
    "    \"\"\"\n",
    "    Calculate the softmax activation function\n",
    "    Return the activation output, activation input and the type of activation function.\n",
    "    \"\"\"\n",
    "    new_max = np.exp(linear_z - np.max(linear_z, axis = 0, keepdims = True))\n",
    "    return new_max / np.sum(new_max, axis = 0, keepdims = True), linear_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_activation_forward(activation_prev, weights, biases, hyperparameters):\n",
    "    \"\"\"\n",
    "    Calculate the softmax activation function\n",
    "    Return the activation output, activation input and the type of activation function.\n",
    "    \"\"\"\n",
    "    linear_z, linear_cache = conv_forward(activation_prev, weights, biases, hyperparameters)\n",
    "    activation, activation_cache = activation_relu(linear_z)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return activation, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(activation_prev, hyperparameters):\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = activation_prev.shape\n",
    "    f, stride, mode = int(hyperparameters['f']), int(hyperparameters['stride']), hyperparameters['mode']\n",
    "    n_H = (n_H_prev - f) // stride + 1\n",
    "    n_W = (n_W_prev - f) // stride + 1\n",
    "    n_C= n_C_prev\n",
    "    activation = np.zeros((m, n_H, n_W, n_C))\n",
    "    for i in range(m):\n",
    "        act_prev = activation_prev[i]\n",
    "        for h in range(n_H):\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "            for w in range(n_W):\n",
    "                horiz_start = w * stride\n",
    "                horiz_end = horiz_start + f\n",
    "                for c in range(n_C):\n",
    "                    act_prev_slice = act_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    if mode == 'max':\n",
    "                        activation[i, h, w, c] = np.max(act_prev_slice)\n",
    "                    elif mode == 'average':\n",
    "                        activation[i, h, w, c] = np.mean(act_prev_slice)\n",
    "                    else:\n",
    "                        raise Exception('You should only use max-pooling or average pooling.')\n",
    "    cache = (activation_prev, hyperparameters)\n",
    "    assert(activation.shape == (m, n_H, n_W, n_C))\n",
    "    return activation, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(activation, weight, bias):\n",
    "    \"\"\"\n",
    "    Find the result of the net input function.\n",
    "    Store the activation input, weight and bias.\n",
    "    \"\"\"\n",
    "    linear_z = np.dot(weight, activation) + bias\n",
    "    assert(linear_z.shape == (weight.shape[0], activation.shape[1]))\n",
    "    cache = (activation, weight, bias)\n",
    "    return linear_z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_forward(activation_prev, weight, bias, activation_type):\n",
    "    \"\"\"\n",
    "    Calculate the activation output\n",
    "    Store the activation output and activation input in the cache.\n",
    "    \"\"\"\n",
    "    linear_z, linear_cache = linear_forward(activation_prev, weight, bias)\n",
    "    if activation_type == \"relu\":\n",
    "        activation, activation_cache = activation_relu(linear_z)\n",
    "    elif activation_type == \"sigmoid\":\n",
    "        activation, activation_cache = activation_sigmoid(linear_z)\n",
    "    elif activation_type == \"softmax\":\n",
    "        activation, activation_cache = activation_softmax(linear_z)\n",
    "    assert(activation.shape == (weight.shape[0], activation_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return activation, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_forward_model(train_x, weight_bias, model, nn_class = 2):\n",
    "    \"\"\"\n",
    "    Simulate the forward propagation\n",
    "    Store the activation output and activation input and activation type in the collective cache.\n",
    "    \"\"\"\n",
    "    assert(nn_class > 1)\n",
    "    caches = []\n",
    "    activation = train_x\n",
    "    for layer in list(model.keys())[1:]:\n",
    "        if type(layer) == int and layer > 0:\n",
    "            for comp in model[layer].keys():\n",
    "                activation_cnn = activation\n",
    "                if comp[:-1] == 'conv':\n",
    "                    activation, cache = cnn_activation_forward(activation_cnn, weight_bias['W'+str(layer)], weight_bias['b'+str(layer)], model[layer][comp])\n",
    "                elif comp[:-1] == 'pool':\n",
    "                    activation, cache = pool_forward(activation_cnn, model[layer][comp])\n",
    "                caches.append(cache)\n",
    "        elif layer == 'fc0':\n",
    "            activation = np.reshape(activation, (-1, activation.shape[0]))\n",
    "        elif layer[:-1] == 'fc':\n",
    "            activation_prev = activation\n",
    "            activation, cache = activation_forward(activation_prev, weight_bias['W' + layer.upper()], weight_bias['b' + layer.upper()], model[layer]['activation'])\n",
    "            caches.append(cache)\n",
    "    print(activation.shape)\n",
    "    return activation, caches    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(activation_layer, Y, last_type):\n",
    "    \"\"\"\n",
    "    Compute the cost of output according to the ground truth.\n",
    "    \"\"\"\n",
    "    if last_type == \"softmax\":\n",
    "        cost = -np.sum(Y * np.log(activation_layer))\n",
    "    else:\n",
    "        cost = -np.sum(Y * np.log(0.1 + activation_layer)  + (1 - Y) * np.log(1.1 - activation_layer)) / Y.shape[1]\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dz_linear, cache):\n",
    "    \"\"\"\n",
    "    Calculate the change of weight, bias and activation with respect to the cost function.\n",
    "    \"\"\"\n",
    "    activation_prev, weight, bias = cache\n",
    "    train_size =  activation_prev.shape[1]\n",
    "    dweight = np.dot(dz_linear, activation_prev.T) / train_size\n",
    "    dbias = np.sum(dz_linear, axis = 1, keepdims = True) / train_size\n",
    "    dactivation_prev = np.dot(weight.T, dz_linear)\n",
    "    assert(dactivation_prev.shape == activation_prev.shape)\n",
    "    assert(dweight.shape == weight.shape)\n",
    "    assert(dbias.shape == bias.shape)\n",
    "    return dactivation_prev, dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dactivation, cache):\n",
    "    \"\"\"\n",
    "    Calculate the sigmoid activation backpropagation function\n",
    "    Return the change of activation.\n",
    "    \"\"\"\n",
    "    sigmoid_cache = activation_sigmoid(cache)[0]\n",
    "    return dactivation * sigmoid_cache * (1 - sigmoid_cache) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dactivation, cache, leaky_rate=0):\n",
    "    \"\"\"\n",
    "    Calculate the relu and leaky relu activation backpropagation function\n",
    "    Return the change of activation.\n",
    "    \"\"\"\n",
    "    relu_cache = np.where(cache < 0, leaky_rate, 1)\n",
    "    return dactivation * relu_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dactivation, cache, activation_type, leaky_rate=0):\n",
    "    \"\"\"\n",
    "    Calculate the activation output\n",
    "    Store the activation output and activation input in the cache.\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation_type == \"relu\":\n",
    "        dz = relu_backward(dactivation, activation_cache, leaky_rate)\n",
    "    elif activation_type == \"sigmoid\":\n",
    "        dz = sigmoid_backward(dactivation, activation_cache)\n",
    "    dactivation_prev, dweight, dbias = linear_backward(dz, linear_cache)\n",
    "    return dactivation_prev, dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_backward(dz, cache):\n",
    "    (activation_prev, weights, biases, hyperparameters) = cache\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = activation_prev.shape\n",
    "    (f, f, n_C_prev, n_C) = weights.shape\n",
    "    stride = int(hyperparameters['stride'])\n",
    "    if hyperparameters['pad'] == 'VALID':\n",
    "        pad = 0\n",
    "    else:\n",
    "        pad = (f - 1) // 2\n",
    "    (m, n_H, n_W, n_C) = dz.shape\n",
    "    dactivation_prev = np.zeros(activation_prev.shape)\n",
    "    dweight = np.zeros(weights.shape)\n",
    "    dbias = np.zeros(biases.shape)\n",
    "    activation_prev_pad = zero_pad(activation_prev, pad)\n",
    "    dactivation_prev_pad = zero_pad(dactivation_prev, pad)\n",
    "    for i in range(m):\n",
    "        act_prev_pad = activation_prev_pad[i]\n",
    "        dact_prev_pad = dactivation_prev_pad[i]\n",
    "        for h in range(n_H):\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "            for w in range(n_W):\n",
    "                horiz_start = w * stride\n",
    "                horiz_end = horiz_start + f\n",
    "                for c in range(n_C):\n",
    "                    activation_slice = act_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    dact_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += weights[...,c] * dz[i, h, w, c]\n",
    "                    dweight[...,c] += activation_slice * dz[i, h, w, c]\n",
    "                    dbias[..., c] += dz[i, h, w, c]\n",
    "        dactivation_prev[i, :, :, :] = dact_prev_pad[pad:dact_prev_pad.shape[0]-pad, pad:dact_prev_pad.shape[1]-pad, :]\n",
    "    assert(dactivation_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
    "    return dactivation_prev, dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_activation_backward(dactivation, cache, leaky_rate=0):\n",
    "    \"\"\"\n",
    "    Calculate the activation output\n",
    "    Store the activation output and activation input in the cache.\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    dz = relu_backward(dactivation, activation_cache, leaky_rate)\n",
    "    dactivation_prev, dweight, dbias = conv_backward(dz, linear_cache)\n",
    "    return dactivation_prev, dweight, dbias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_backward(train_x):\n",
    "    return (train_x == np.max(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_backward(dz, shape):\n",
    "    return np.ones(shape) * (np.sum(dz) / shape[0] / shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_backward(dactivation, cache, mode='max'):\n",
    "    (activation_prev, hyperparameters) = cache\n",
    "    stride, f = int(hyperparameters['stride']), int(hyperparameters['f'])\n",
    "    m, n_H_prev, n_W_prev, n_C_prev = activation_prev.shape\n",
    "    m, n_H, n_W, n_C = dactivation.shape\n",
    "    dactivation_prev = np.zeros(activation_prev.shape)\n",
    "    for i in range(m):\n",
    "        act_prev = activation_prev[i]\n",
    "        for h in range(n_H):\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "            for w in range(n_W):\n",
    "                horiz_start = w * stride\n",
    "                horiz_end = horiz_start + f\n",
    "                for c in range(n_C):\n",
    "                    if mode == 'max':\n",
    "                        act_prev_slice = act_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        mask = max_backward(act_prev_slice)\n",
    "                        dactivation_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += mask * dactivation[i, h, w, c]\n",
    "                    elif mode == 'average':\n",
    "                        dactivation_prev[i, vert_start:vert_end, horiz_start:horiz_end, c] += average_backward(dactivation[i, h, w, c], (f, f))\n",
    "    assert(dactivation_prev.shape == activation_prev.shape)\n",
    "    return dactivation_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_backward(activation, Y, caches, model):\n",
    "    \"\"\"\n",
    "    Simulate the back propagation.\n",
    "    Find the gradients with respect to the cost function.\n",
    "    \"\"\"\n",
    "    grads = {}\n",
    "    length = len(caches)\n",
    "    model_no = 0\n",
    "    dlast_activation = - (np.divide(Y + 1e-15, activation + 1e-15) - np.divide(1 - Y + 1e-15, 1 - activation + 1e-15))\n",
    "    current_cache = caches[length - 1]\n",
    "    models = list(reversed(list(model.keys())))\n",
    "    if model[models[model_no]]['activation'] != \"softmax\":\n",
    "        grads[\"dA\" + models[model_no + 1].upper()], grads[\"dW\" + models[model_no].upper()], grads[\"db\" + models[model_no].upper()] = linear_activation_backward(dlast_activation, current_cache, model[models[model_no]]['activation'])\n",
    "    else:\n",
    "        grads[\"dA\" + models[model_no + 1].upper()], grads[\"dW\" + models[model_no].upper()], grads[\"db\" + models[model_no].upper()] = linear_backward(activation - Y, current_cache[0])\n",
    "    length -= 1\n",
    "    mno = 1\n",
    "    while mno < len(models):\n",
    "        current_cache = caches[length - 1]\n",
    "        if type(models[mno]) == str and models[mno][:-1] == \"fc\" and models[mno] != 'fc0':\n",
    "            dactivation_prev_temp, dweight_prev_temp, dbias_prev_temp = linear_activation_backward(grads[\"dA\" + models[mno].upper()], current_cache, model[models[mno]]['activation'])\n",
    "            length -= 1\n",
    "            grads[\"dA\" + models[mno + 1].upper()], grads[\"dW\" + models[mno].upper()], grads[\"db\" + models[mno].upper()] = dactivation_prev_temp, dweight_prev_temp, dbias_prev_temp\n",
    "            mno += 1\n",
    "        elif models[mno] == 'fc0':\n",
    "            grads[\"dA\" + str(models[mno + 1]).upper()] = grads[\"dA\" + str(models[mno]).upper()].reshape(model[models[mno]]['shape'])\n",
    "            mno += 1\n",
    "        else:\n",
    "            if models[mno] == 0:\n",
    "                break\n",
    "            layers = list(reversed(list(model[models[mno]].keys())))\n",
    "            for lyr in layers:\n",
    "                current_cache = caches[length - 1]\n",
    "                if lyr[:-1] == 'pool':\n",
    "                    dactivation_prev_temp = pool_backward(grads[\"dA\" + str(models[mno]).upper()], current_cache, model[models[mno]][lyr]['mode'])\n",
    "                    length -= 1\n",
    "                    grads[\"dA\" + str(models[mno]).upper()] = dactivation_prev_temp\n",
    "                elif lyr[:-1] == 'conv':\n",
    "                    dactivation_prev_temp, dweight_prev_temp, dbias_prev_temp = cnn_activation_backward(grads[\"dA\" + str(models[mno]).upper()], current_cache)\n",
    "                    length -= 1\n",
    "                    grads[\"dA\" + str(models[mno + 1]).upper()], grads[\"dW\" + str(models[mno]).upper()], grads[\"db\" + str(models[mno]).upper()] = dactivation_prev_temp, dweight_prev_temp, dbias_prev_temp\n",
    "            mno += 1\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate, model):\n",
    "    \"\"\"\n",
    "    Update the parameters.\n",
    "    Return the updated parameters.\n",
    "    \"\"\"\n",
    "    for layer in list(model.keys())[1:]:\n",
    "        if layer == 'fc0':\n",
    "            continue\n",
    "        else:\n",
    "            parameters[\"W\" + str(layer).upper()] = parameters[\"W\" + str(layer).upper()] - learning_rate * grads[\"dW\" + str(layer).upper()]\n",
    "            parameters[\"b\" + str(layer).upper()] = parameters[\"b\" + str(layer).upper()] - learning_rate * grads[\"db\" + str(layer).upper()]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_layer_model(X, Y, nn_class=2, mini_batch_size=64, learning_rate=0.001, num_epochs=3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Create a multi layer model using the prebuild functions.\n",
    "    Do forward propagation and back propogation and update the parameters.\n",
    "    \"\"\"\n",
    "    model = create_cnn_model(X, nn_class)\n",
    "    print(model)\n",
    "    costs = []\n",
    "    seed = 0\n",
    "    parameters = initialize_parameters(model)\n",
    "    for i in range(num_epochs):\n",
    "        seed += 1\n",
    "        minibatches = random_mini_batches(X, Y, mini_batch_size)\n",
    "        cost_total = 0\n",
    "        for minibatch in minibatches:\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            A_Layer, caches = cnn_forward_model(minibatch_X, parameters, model, nn_class)\n",
    "            print(\"CNN Forward Model is finished.\")\n",
    "            if nn_class > 2:\n",
    "                cost_total += compute_cost(A_Layer, minibatch_Y, 'softmax')\n",
    "            else:\n",
    "                cost_total += compute_cost(A_Layer, minibatch_Y, 'sigmoid')\n",
    "            print(\"CNN Compute Cost is finished.\")\n",
    "            grads = cnn_model_backward(A_Layer, minibatch_Y, caches, model)\n",
    "            print(\"CNN Backward Model is finished.\")\n",
    "            parameters = update_parameters(parameters, grads, learning_rate, model)\n",
    "            print(\"CNN Update Parameter is finished.\")\n",
    "        print(\"CNN \" + str(i) + \"th Epoch is finished.\")\n",
    "        cost_avg = cost_total / mini_batch_size\n",
    "        if print_cost:\n",
    "            print('Cost after iteration {}:{}'.format(i, cost_avg))\n",
    "            costs.append(cost_avg)\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel(\"Costs\")\n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.title(\"Learning Rate: \" + str(learning_rate))\n",
    "    plt.show()\n",
    "    return parameters, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many convolutional layers do you want: 2\n",
      "State the layer type : conv\n",
      "State the layer size 1 : 5\n",
      "State the stride size 1 : 1\n",
      "State the pad type 1 : valid\n",
      "State the channel size 1 : 6\n",
      "State the layer type : pool\n",
      "State the layer size 1 : 2\n",
      "State the stride size 1 : 2\n",
      "State the type of layer 1 and pooling layer 1 : max\n",
      "State the layer type : conv\n",
      "State the layer size 2 : 5\n",
      "State the stride size 2 : 1\n",
      "State the pad type 2 : valid\n",
      "State the channel size 2 : 16\n",
      "State the layer type : pool\n",
      "State the layer size 2 : 2\n",
      "State the stride size 2 : 2\n",
      "State the type of layer 2 and pooling layer 1 : max\n",
      "State the layer type : conv\n",
      "The last convolution layer is not added, the CNN model is constructed.\n",
      "How many fully connected layers do you want (output layer included): 3\n",
      "State the fully connected layer 1 size: 120\n",
      "State the fully connected layer 2 size: 84\n",
      "{0: {'conv0': {'channel_size': 1}}, 1: {'conv1': {'layer_type': 'conv', 'f': 5, 'stride': 1, 'pad': 'VALID', 'channel_size': 6}, 'pool1': {'layer_type': 'pool', 'f': 2, 'stride': 2, 'mode': 'max'}}, 2: {'conv2': {'layer_type': 'conv', 'f': 5, 'stride': 1, 'pad': 'VALID', 'channel_size': 16}, 'pool1': {'layer_type': 'pool', 'f': 2, 'stride': 2, 'mode': 'max'}}, 'fc0': {'shape': (-1, 5, 5, 16), 'fc_size': 400}, 'fc1': {'activation': 'relu', 'fc_size': 120}, 'fc2': {'activation': 'relu', 'fc_size': 84}, 'fc3': {'activation': 'softmax', 'fc_size': 10}}\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1632)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "CNN 0th Epoch is finished.\n",
      "Cost after iteration 0:137.29164894201412\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1632)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "CNN 1th Epoch is finished.\n",
      "Cost after iteration 1:137.21742139739607\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n",
      "CNN Backward Model is finished.\n",
      "CNN Update Parameter is finished.\n",
      "(10, 1024)\n",
      "CNN Forward Model is finished.\n",
      "CNN Compute Cost is finished.\n"
     ]
    }
   ],
   "source": [
    "parameters, model = multi_layer_model(train_x, train_y, 10, 1024, 0.001, num_epochs=30, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, Y, weight_bias, model, nn_class = 2, data=\"Train\"):\n",
    "    \"\"\"\n",
    "    Predict the result using validation data.\n",
    "    Find the accuracy of the data.\n",
    "    \"\"\"\n",
    "    A_Layer, caches = cnn_forward_model(X, weight_bias, model, nn_class)\n",
    "    A_Layer = np.where(A_Layer > 0.5, 1, 0)\n",
    "    predicted = (1 - np.count_nonzero(A_Layer - Y) / A_Layer.shape[1]) * 100\n",
    "    print(data + \" Accuracy: \" + str(predicted))\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_image_prediction(img_addr, Y, num_px, parameters, model, nn_class, data):\n",
    "    \"\"\"\n",
    "    Predict the result using a custom image.\n",
    "    Find the accuracy of the image.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(img_addr)\n",
    "    img = cv2.resize(img, (num_px, num_px), interpolation=cv2.INTER_CUBIC)# resize to (128,128)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # cv2 load images as BGR, convert it to RGB\n",
    "    plt.imshow(img)\n",
    "    img = np.reshape(img, (1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "    my_image = img/255.\n",
    "    my_predicted_image = predict(my_image, Y, parameters, model, 2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = predict(train_x, train_y, parameters, model, 2, \"Train\")\n",
    "predict_test = predict(valid_x, valid_y, parameters, model, 2, \"Test\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
